{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488fc22f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "import math\n",
    "from copy import deepcopy\n",
    "from collections import OrderedDict\n",
    "from sys import stderr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.style.use('classic')\n",
    "# for type hint\n",
    "from torch import Tensor\n",
    "\n",
    "CUDA = True\n",
    "device = torch.device(\"cuda\" if CUDA else \"cpu\")\n",
    "\n",
    "\n",
    "### https://www.zijianhu.com/post/pytorch/ema/\n",
    "class EMA(nn.Module):\n",
    "    def __init__(self, model: nn.Module, decay: float):\n",
    "        super().__init__()\n",
    "        self.decay = decay\n",
    "\n",
    "        self.model = model\n",
    "        self.shadow = deepcopy(self.model)\n",
    "\n",
    "        for param in self.shadow.parameters():\n",
    "            param.detach_()\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def update(self):\n",
    "        if not self.training:\n",
    "            print(\"EMA update should only be called during training\", file=stderr, flush=True)\n",
    "            return\n",
    "\n",
    "        model_params = OrderedDict(self.model.named_parameters())\n",
    "        shadow_params = OrderedDict(self.shadow.named_parameters())\n",
    "\n",
    "        # check if both model contains the same set of keys\n",
    "        assert model_params.keys() == shadow_params.keys()\n",
    "\n",
    "        for name, param in model_params.items():\n",
    "            # see https://www.tensorflow.org/api_docs/python/tf/train/ExponentialMovingAverage\n",
    "            # shadow_variable -= (1 - decay) * (shadow_variable - variable)\n",
    "            shadow_params[name].sub_((1. - self.decay) * (shadow_params[name] - param))\n",
    "\n",
    "        model_buffers = OrderedDict(self.model.named_buffers())\n",
    "        shadow_buffers = OrderedDict(self.shadow.named_buffers())\n",
    "\n",
    "        # check if both model contains the same set of keys\n",
    "        assert model_buffers.keys() == shadow_buffers.keys()\n",
    "\n",
    "        for name, buffer in model_buffers.items():\n",
    "            # buffers are copied\n",
    "            shadow_buffers[name].copy_(buffer)\n",
    "\n",
    "    def forward(self, *args, **kwargs):\n",
    "        \n",
    "        if self.training:\n",
    "            return self.model(*args, **kwargs)\n",
    "        else:\n",
    "            return self.shadow(*args, **kwargs)\n",
    "\n",
    "\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, input_dim, layer_widths, activate_final = False, activation_fn=F.relu):\n",
    "        super(MLP, self).__init__()\n",
    "        layers = []\n",
    "        prev_width = input_dim\n",
    "        for layer_width in layer_widths:\n",
    "            layers.append(torch.nn.Linear(prev_width, layer_width))\n",
    "            # # same init for everyone\n",
    "            # torch.nn.init.constant_(layers[-1].weight, 0)\n",
    "            prev_width = layer_width\n",
    "        self.input_dim = input_dim\n",
    "        self.layer_widths = layer_widths\n",
    "        self.layers = torch.nn.ModuleList(layers)\n",
    "        self.activate_final = activate_final\n",
    "        self.activation_fn = activation_fn\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for i, layer in enumerate(self.layers[:-1]):\n",
    "            x = self.activation_fn(layer(x))\n",
    "        x = self.layers[-1](x)\n",
    "        if self.activate_final:\n",
    "            x = self.activation_fn(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def get_timestep_embedding(timesteps, embedding_dim=128):\n",
    "    \"\"\"\n",
    "      From Fairseq.\n",
    "      Build sinusoidal embeddings.\n",
    "      This matches the implementation in tensor2tensor, but differs slightly\n",
    "      from the description in Section 3.5 of \"Attention Is All You Need\".\n",
    "      https://github.com/pytorch/fairseq/blob/master/fairseq/modules/sinusoidal_positional_embedding.py\n",
    "    \"\"\"\n",
    "    half_dim = embedding_dim // 2\n",
    "    emb = math.log(10000) / (half_dim - 1)\n",
    "    emb = torch.exp(torch.arange(half_dim, dtype=torch.float, device=timesteps.device) * -emb)\n",
    "\n",
    "    emb = timesteps.float() * emb.unsqueeze(0)\n",
    "    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=-1)\n",
    "    if embedding_dim % 2 == 1:  # zero pad\n",
    "        emb = F.pad(emb, [0,1])\n",
    "\n",
    "    return emb\n",
    "\n",
    "\n",
    "class ScoreNetworkEnergy(torch.nn.Module):\n",
    "    def __init__(self, encoder_layers=[256,256], pos_dim=128, decoder_layers=[256,256], x_dim=1, n_cond=1):\n",
    "\n",
    "        super().__init__()\n",
    "        self.temb_dim = pos_dim\n",
    "        t_enc_dim = pos_dim *2\n",
    "        self.locals = [encoder_layers, pos_dim, decoder_layers, x_dim]\n",
    "        self.n_cond = n_cond\n",
    "\n",
    "\n",
    "        self.net = MLP(3 * t_enc_dim + 1,\n",
    "                       layer_widths=decoder_layers +[x_dim],\n",
    "                       activate_final = False,\n",
    "                       activation_fn=torch.nn.LeakyReLU())\n",
    "\n",
    "        self.t_encoder = MLP(pos_dim,\n",
    "                             layer_widths=encoder_layers +[t_enc_dim],\n",
    "                             activate_final = False,\n",
    "                             activation_fn=torch.nn.LeakyReLU())\n",
    "\n",
    "        self.x_encoder = MLP(x_dim,\n",
    "                             layer_widths=encoder_layers +[t_enc_dim],\n",
    "                             activate_final = False,\n",
    "                             activation_fn=torch.nn.LeakyReLU())\n",
    "            \n",
    "        self.e_encoder = MLP(1,\n",
    "                             layer_widths=encoder_layers +[t_enc_dim],\n",
    "                             activate_final = False,\n",
    "                             activation_fn=torch.nn.LeakyReLU())\n",
    "        \n",
    "        \n",
    "    def forward(self, x, t, cond=None, selfcond=None):\n",
    "        if len(x.shape) == 1:\n",
    "            x = x.unsqueeze(0)\n",
    "\n",
    "        if len(selfcond.shape) == 1:\n",
    "            selfcond = selfcond.unsqueeze(0)\n",
    "\n",
    "        temb = get_timestep_embedding(t, self.temb_dim)\n",
    "        temb = self.t_encoder(temb)\n",
    "        \n",
    "        xemb = self.x_encoder(x)\n",
    "        \n",
    "            \n",
    "        if self.n_cond > 0:\n",
    "            eemb = cond\n",
    "            eemb = self.e_encoder(eemb)\n",
    "            h = torch.cat([xemb, temb, selfcond, eemb], -1)\n",
    "        else:\n",
    "            h = torch.cat([xemb ,temb, selfcond], -1)\n",
    "                \n",
    "        out = self.net(h) \n",
    "        return out\n",
    "        \n",
    "  \n",
    "        \n",
    "        \n",
    "class ScoreNetworkConv(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, x_dim=100, n_cond=0):\n",
    "        super().__init__()\n",
    "        self.conv_dof = 32\n",
    "        self.n_cond = n_cond\n",
    "        \n",
    "        self.temb_dim = 128\n",
    "        self.encoder_layers=[256,256]\n",
    "        self.t_enc_dim = self.conv_dof\n",
    "        \n",
    "        self.bias = False\n",
    "        \n",
    "        self.t_encoder = MLP(self.temb_dim,\n",
    "                             layer_widths=self.encoder_layers +[self.t_enc_dim],\n",
    "                             activate_final = False,\n",
    "                             activation_fn=torch.nn.LeakyReLU())\n",
    "\n",
    "        self.con_x_encoder1 = torch.nn.Conv2d(1, self.conv_dof, (3, 3), stride=(1, 1), \n",
    "                                              padding=(1, 1),bias=self.bias)\n",
    "        self.con_x_encoder2 = torch.nn.Conv2d(self.conv_dof, self.conv_dof, (3, 3), stride=(1, 1), \n",
    "                                              padding=(1, 1),bias=self.bias)\n",
    "        self.con_x_encoder3 = torch.nn.Conv2d(self.conv_dof, self.conv_dof, (3, 3), stride=(1, 1), \n",
    "                                              padding=(1, 1),bias=self.bias)\n",
    "        self.con_x_encoder4 = torch.nn.Conv2d(self.conv_dof, self.conv_dof, (3, 3), stride=(1, 1), \n",
    "                                              padding=(1, 1),bias=self.bias)\n",
    "        \n",
    "        \n",
    "        self.con_x_decoder1 = torch.nn.Conv2d(self.conv_dof*2+self.n_cond+1, self.conv_dof, (3, 3), stride=(1, 1), \n",
    "                                              padding=(1, 1),bias=self.bias)\n",
    "        self.con_x_decoder2 = torch.nn.Conv2d(self.conv_dof, self.conv_dof, (3, 3), stride=(1, 1), \n",
    "                                              padding=(1, 1),bias=self.bias)\n",
    "        self.con_x_decoder3 = torch.nn.Conv2d(self.conv_dof, self.conv_dof, (3, 3), stride=(1, 1), \n",
    "                                              padding=(1, 1),bias=self.bias)\n",
    "        self.con_x_decoder4 = torch.nn.Conv2d(self.conv_dof, 1, (3, 3), stride=(1, 1), \n",
    "                                              padding=(1, 1),bias=self.bias)\n",
    "        \n",
    "        self.leakyReLU = torch.nn.LeakyReLU()\n",
    "\n",
    "        \n",
    "        \n",
    "    def forward(self, x, t, cond=None, selfcond=None):\n",
    "        if len(x.shape) == 1:\n",
    "            x = x.unsqueeze(0)\n",
    "\n",
    "        if self.n_cond > 0:\n",
    "            cond = cond.view(-1, self.n_cond, 1, 1).expand(-1, -1, 10, 10)\n",
    "\n",
    "        temb = get_timestep_embedding(t, self.temb_dim)\n",
    "        #print(t.size(), temb.size())\n",
    "        \n",
    "        temb = self.t_encoder(temb).view(-1, self.t_enc_dim, 1, 1).expand(-1, -1, 10, 10)\n",
    "        \n",
    "        xemb = self.leakyReLU(self.con_x_encoder1(x))\n",
    "        xemb = self.leakyReLU(self.con_x_encoder2(xemb))\n",
    "        xemb = self.leakyReLU(self.con_x_encoder3(xemb))\n",
    "        xemb = (self.con_x_encoder4(xemb))\n",
    "        \n",
    "        if self.n_cond > 0:\n",
    "            h = torch.cat([xemb, temb, selfcond, cond], 1)\n",
    "        else:\n",
    "            h = torch.cat([xemb, temb, selfcond], 1)\n",
    "            \n",
    "        out = self.leakyReLU(self.con_x_decoder1(h))\n",
    "        out = self.leakyReLU(self.con_x_decoder2(out))\n",
    "        out = self.leakyReLU(self.con_x_decoder3(out))\n",
    "        out = (self.con_x_decoder4(out))\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467be94a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "line_style = {\n",
    "    'Geant4':'dotted',\n",
    "    'GFlash':'-',\n",
    "    'SQuIRELS-E':'-',\n",
    "    'SQuIRELS':'-',\n",
    "}\n",
    "\n",
    "colors = {\n",
    "    'Geant4':'black',\n",
    "    'GFlash':'red',\n",
    "    'SQuIRELS-E':'#2ca25f',\n",
    "    'SQuIRELS':'#7570b3',\n",
    "}\n",
    "\n",
    "\n",
    "from matplotlib import rc\n",
    "rc('text', usetex=True)\n",
    "\n",
    "import matplotlib as mpl\n",
    "rc('font', family='serif')\n",
    "rc('font', size=22)\n",
    "rc('xtick', labelsize=15)\n",
    "rc('ytick', labelsize=15)\n",
    "rc('legend', fontsize=15)\n",
    "\n",
    "# #\n",
    "mpl.rcParams.update({'font.size': 19})\n",
    "#mpl.rcParams.update({'legend.fontsize': 18})\n",
    "\n",
    "\n",
    "mpl.rcParams.update({'figure.titlesize': 11}) \n",
    "mpl.rcParams.update({'xtick.labelsize': 18}) \n",
    "mpl.rcParams.update({'ytick.labelsize': 18}) \n",
    "mpl.rcParams.update({'axes.labelsize': 18}) \n",
    "mpl.rcParams.update({'legend.frameon': False}) \n",
    "mpl.rcParams.update({'lines.linewidth': 2})\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep as hep\n",
    "#hep.set_style(hep.style.CMS)\n",
    "hep.style.use(\"CMS\") \n",
    "\n",
    "mpl.rcParams['text.usetex'] = False\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "#mpl.rcParams['font.family'] = 'Helvetica'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def imageplotting(data_l, data_name_l):\n",
    "    \n",
    "    fig = plt.figure(figsize=(6*len(data_l),6))\n",
    "    fig.set_facecolor('white')\n",
    "    outer = gridspec.GridSpec(1, len(data_l) , wspace=0.2, hspace=0.0)\n",
    "\n",
    "    for (i, (d, d_n)) in enumerate( zip(data_l, data_name_l) ):\n",
    "\n",
    "        subplot = fig.add_subplot(outer[i])\n",
    "\n",
    "        im = subplot.imshow(np.mean(d, 0), norm=LogNorm(vmin=0.001, vmax=20), filternorm=False, interpolation='none', cmap = 'viridis',  origin='lower')\n",
    "        subplot.patch.set_facecolor('white')\n",
    "        subplot.title.set_text(d_n)\n",
    "        subplot.set_xlabel('y [cells]')\n",
    "        subplot.set_ylabel('x [cells]')\n",
    "        fig.colorbar(im)\n",
    "\n",
    "\n",
    "def FormatFig(xlabel,ylabel,ax0):\n",
    "    #Limit number of digits in ticks\n",
    "    # y_loc, _ = plt.yticks()\n",
    "    # y_update = ['%.1f' % y for y in y_loc]\n",
    "    # plt.yticks(y_loc, y_update) \n",
    "    ax0.set_xlabel(xlabel,fontsize=20)\n",
    "    ax0.set_ylabel(ylabel)\n",
    "        \n",
    "\n",
    "    # xposition = 0.9\n",
    "    # yposition=1.03\n",
    "    # text = 'H1'\n",
    "    # WriteText(xposition,yposition,text,ax0)\n",
    "\n",
    "    \n",
    "def SetGrid(ratio=True):\n",
    "    if ratio:\n",
    "        fig = plt.figure(figsize=(9, 9))\n",
    "        gs = gridspec.GridSpec(2, 1, height_ratios=[3,1]) \n",
    "        gs.update(wspace=0.025, hspace=0.1)\n",
    "    else:\n",
    "        fig = plt.figure(figsize=(9, 7))\n",
    "        gs = gridspec.GridSpec(1, 1)\n",
    "    return fig,gs\n",
    "\n",
    "\n",
    "def GetEMD(ref,array,weights_arr,nboot = 100):\n",
    "    from scipy.stats import wasserstein_distance\n",
    "    ds = []\n",
    "    for _ in range(nboot):\n",
    "        #ref_boot = np.random.choice(ref,ref.shape[0])\n",
    "        arr_idx = np.random.choice(range(array.shape[0]),array.shape[0])\n",
    "        array_boot = array[arr_idx]\n",
    "        w_boot = weights_arr[arr_idx]\n",
    "        ds.append(wasserstein_distance(ref,array_boot,v_weights=w_boot))\n",
    "    \n",
    "    return np.mean(ds), np.std(ds)\n",
    "    # mse = np.square(ref-array)/ref\n",
    "    # return np.sum(mse)\n",
    "\n",
    "\n",
    "def get_triangle_distance(x,y,binning):\n",
    "    dist = 0\n",
    "    w = binning[1:] - binning[:-1]\n",
    "    for ib in range(len(x)):\n",
    "        dist+=0.5*w[ib]*(x[ib] - y[ib])**2/(x[ib] + y[ib]) if x[ib] + y[ib] >0 else 0.0\n",
    "    return dist*1e3\n",
    "\n",
    "        \n",
    "def HistRoutine(feed_dict,xlabel='',ylabel='',reference_name='Truth',logy=False,binning=None,label_loc='best',plot_ratio=False,weights=None,uncertainty=None,triangle=True, y_lim_ratio=[0.5,1.5], title='', density=True, y_range=None):\n",
    "    assert reference_name in feed_dict.keys(), \"ERROR: Don't know the reference distribution\"\n",
    "\n",
    "    ref_plot = {'histtype':'stepfilled','alpha':0.2}\n",
    "    other_plots = {'histtype':'step','linewidth':2}\n",
    "    fig,gs = SetGrid(ratio=plot_ratio) \n",
    "    ax0 = plt.subplot(gs[0])\n",
    "\n",
    "    if plot_ratio:\n",
    "        plt.xticks(fontsize=0)\n",
    "        ax1 = plt.subplot(gs[1],sharex=ax0)\n",
    "\n",
    "    \n",
    "    if binning is None:\n",
    "        binning = np.linspace(np.quantile(feed_dict[reference_name],0.0),np.quantile(feed_dict[reference_name],1),30)\n",
    "        \n",
    "    xaxis = [(binning[i] + binning[i+1])/2.0 for i in range(len(binning)-1)]\n",
    "    reference_hist,_ = np.histogram(feed_dict[reference_name],bins=binning,density=density,weights=weights[reference_name])\n",
    "\n",
    "    d_list = []\n",
    "    err_list = []\n",
    "    \n",
    "    maxy = 0    \n",
    "    for ip,plot in enumerate(feed_dict.keys()):\n",
    "        plot_style = ref_plot if reference_name == plot else other_plots\n",
    "        if weights is not None:\n",
    "            dist,_,_=ax0.hist(feed_dict[plot],bins=binning,label=plot,linestyle=line_style[plot],color=colors[plot],density=density,weights=weights[plot],**plot_style)\n",
    "        else:\n",
    "            dist,_,_=ax0.hist(feed_dict[plot],bins=binning,label=plot,linestyle=line_style[plot],color=colors[plot],density=density,**plot_style)\n",
    "\n",
    "            \n",
    "        if triangle:\n",
    "            print(plot)\n",
    "            d,err = GetEMD(feed_dict[reference_name][:100000],feed_dict[plot][:100000],weights[plot][:100000])\n",
    "            print(\"EMD distance is: {}+-{}\".format(d,err))\n",
    "            #d = get_triangle_distance(dist,reference_hist,binning)\n",
    "            #print(\"Triangular distance is: {0:.2g}\".format(d))\n",
    "            if not reference_name == plot:\n",
    "                #label_list.append(plot + ' EMD: {0:.2g} $\\pm$ {1:.2g}'.format(d, err))\n",
    "                #label_list.append(plot)\n",
    "                d_list.append(d)\n",
    "                #label_list.append(' $\\pm$ ')\n",
    "                err_list.append(err)\n",
    "                \n",
    "            if reference_name == plot:\n",
    "                #label_list.append(plot + ' EMD: {0:.2g} $\\pm$ {1:.2g}'.format(d, err))\n",
    "                #label_list.append(plot)\n",
    "                d_list.append(d)\n",
    "                #label_list.append(' $\\pm$ ')\n",
    "                err_list.append(err)\n",
    "                #label_list.append(plot)\n",
    "\n",
    "            \n",
    "        if np.max(dist) > maxy:\n",
    "            maxy = np.max(dist)\n",
    "            \n",
    "        if plot_ratio:\n",
    "            if reference_name!=plot:\n",
    "                ratio = np.ma.divide(dist,reference_hist).filled(0)                \n",
    "                ax1.plot(xaxis,ratio,color=colors[plot],marker='+',ms=8,lw=0,markerfacecolor='none',markeredgewidth=3)\n",
    "                if uncertainty is not None:\n",
    "                    for ibin in range(len(binning)-1):\n",
    "                        xup = binning[ibin+1]\n",
    "                        xlow = binning[ibin]\n",
    "                        ax1.fill_between(np.array([xlow,xup]),\n",
    "                                         uncertainty[ibin],-uncertainty[ibin], alpha=0.3,color='k')    \n",
    " \n",
    "    len_list = []\n",
    "    \n",
    "    for err in (err_list):\n",
    "        #print('{0:.2g}'.format(err))\n",
    "        #print(len('{0:.2g}'.format(err)))\n",
    "        temp = '{0:.2g}'.format(err)\n",
    "        if 'e' in temp:\n",
    "            len_list.append(int(temp[-1])+2)\n",
    "        else:\n",
    "            len_list.append(len(temp))\n",
    "     \n",
    "    precision = max(len_list)-2\n",
    "\n",
    "        \n",
    "    label_list = []\n",
    "    \n",
    "    for ip,plot in enumerate(feed_dict.keys()):\n",
    "        label_list.append(plot)\n",
    "\n",
    "    for d in (d_list):\n",
    "        label_list.append('EMD: {0:.{1}f}'.format(d, precision))\n",
    "        ax0.plot(binning[5], -100000, alpha=0.0)\n",
    "\n",
    "    for ip,plot in enumerate(feed_dict.keys()):\n",
    "        label_list.append(' $\\pm$ ')\n",
    "        ax0.plot(binning[5], -100000, alpha=0.0)\n",
    "\n",
    "    for err in (err_list):\n",
    "        label_list.append('{0:.{1}f}'.format(err, precision))\n",
    "        ax0.plot(binning[5], -100000, alpha=0.0)\n",
    "\n",
    "    out = ' ' \n",
    "    for ip,plot in enumerate(feed_dict.keys()):\n",
    "        out = out + (' & {0:.{1}f}'.format(d_list[ip], precision)) + '$\\pm$' + ('{0:.{1}f}'.format(err_list[ip], precision))\n",
    "    \n",
    "    print('{}, {} , {}: '.format(xlabel, title, plot) + out)\n",
    "    \n",
    "    out = ' ' \n",
    "    for ip,plot in enumerate(feed_dict.keys()):\n",
    "        temp = '{0:.1g}'.format(err_list[ip])\n",
    "        if 'e' in temp:\n",
    "            precision = temp[-1]\n",
    "        else:\n",
    "            precision = (len(temp))-2\n",
    "        out = out + (' & {0:.{1}f}'.format(d_list[ip], precision)) + '(' + ('{0:.{1}f})'.format(err_list[ip], precision))[-2:]\n",
    "    \n",
    "    print('{}, {} , {}: '.format(xlabel, title, plot) + out)\n",
    "    \n",
    "\n",
    "    if logy:\n",
    "        ax0.set_yscale('log')\n",
    "\n",
    "    if triangle:\n",
    "        ax0.legend(loc=label_loc,fontsize=16,ncol=4, labels=label_list, columnspacing=-1.15)\n",
    "    else:\n",
    "        ax0.legend(loc=label_loc,fontsize=16,ncol=1)\n",
    "\n",
    "    ax0.title.set_text(title)\n",
    "    ax0.title.set_size(25)\n",
    "    \n",
    "    if y_range is None:\n",
    "        ax0.set_ylim(0,1.3*maxy)\n",
    "    else:\n",
    "        ax0.set_ylim(y_range[0], y_range[1])\n",
    "    \n",
    "    if plot_ratio:\n",
    "        FormatFig(xlabel = \"\", ylabel = ylabel,ax0=ax0) \n",
    "        plt.ylabel('Ratio to Truth')\n",
    "        plt.axhline(y=1.0, color='r', linestyle='-',linewidth=1)\n",
    "        # plt.axhline(y=10, color='r', linestyle='--',linewidth=1)\n",
    "        # plt.axhline(y=-10, color='r', linestyle='--',linewidth=1)\n",
    "        plt.ylim(y_lim_ratio)\n",
    "        plt.xlabel(xlabel)\n",
    "    else:\n",
    "        FormatFig(xlabel = xlabel, ylabel = ylabel,ax0=ax0) \n",
    "       \n",
    "    try:\n",
    "        ax0.ticklabel_format(useOffset=False)\n",
    "    except:\n",
    "        pass\n",
    "    return fig,ax0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def ScatterRoutine(xdata, ydata, data_label ,xlabel='',ylabel='',label_loc='best', title=''):\n",
    "\n",
    "    fig,gs = SetGrid(ratio=False) \n",
    "    ax0 = plt.subplot(gs[0])\n",
    "\n",
    "    ax0.scatter(xdata, ydata, label=data_label)\n",
    "\n",
    "    ax0.legend(loc=label_loc,fontsize=16,ncol=2)\n",
    "    ax0.title.set_text(title)\n",
    "    ax0.title.set_size(25)\n",
    "    FormatFig(xlabel = xlabel, ylabel = ylabel,ax0=ax0) \n",
    "       \n",
    "    ax0.ticklabel_format(useOffset=False)\n",
    "    return fig,ax0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7a08d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path_gflash = './data/run_GFlash01_100k_10_100GeV_eval_full'\n",
    "file_path_g4 = './data/run_Geant_100k_10_100GeV_eval_full'\n",
    "file_name = '.npy'\n",
    "\n",
    "energy_voxel_g4 = np.load(file_path_g4 + file_name)[:, 0:100].astype(np.float32)\n",
    "energy_voxel_gflash  = np.load(file_path_gflash + file_name)[:, 0:100].astype(np.float32)\n",
    "\n",
    "energy_particle_g4 = np.load(file_path_g4 + file_name)[:, 200:201].astype(np.float32)/10000.0\n",
    "energy_particle_gflash  = np.load(file_path_gflash + file_name)[:, 200:201].astype(np.float32)/10000.0\n",
    "\n",
    "\n",
    "# sort by incident energy to define pairs\n",
    "mask_energy_particle_g4 = np.argsort(energy_particle_g4, axis=0)[:,0]\n",
    "mask_energy_particle_gflash = np.argsort(energy_particle_gflash, axis=0)[:,0]\n",
    "\n",
    "energy_particle_g4 = energy_particle_g4[mask_energy_particle_g4]\n",
    "energy_particle_gflash = energy_particle_gflash[mask_energy_particle_gflash]\n",
    "\n",
    "energy_voxel_g4 = energy_voxel_g4[mask_energy_particle_g4]\n",
    "energy_voxel_gflash = energy_voxel_gflash[mask_energy_particle_gflash]\n",
    "\n",
    "# reshuffle consistently\n",
    "mask_shuffle = np.random.permutation(energy_particle_g4.shape[0])\n",
    "\n",
    "energy_particle_g4 = energy_particle_g4[mask_shuffle]\n",
    "energy_particle_gflash = energy_particle_gflash[mask_shuffle]\n",
    "\n",
    "energy_voxel_g4 = energy_voxel_g4[mask_shuffle]\n",
    "energy_voxel_gflash = energy_voxel_gflash[mask_shuffle]\n",
    "\n",
    "\n",
    "\n",
    "energy_g4 = np.sum(energy_voxel_g4, 1, keepdims=True)\n",
    "energy_gflash = np.sum(energy_voxel_gflash, 1, keepdims=True)\n",
    "\n",
    "\n",
    "energy_voxel_g4 = np.reshape(energy_voxel_g4, (-1, 1, 10, 10))\n",
    "energy_voxel_gflash = np.reshape(energy_voxel_gflash, (-1, 1, 10, 10))\n",
    "\n",
    "\n",
    "energy_voxel_g4 = energy_voxel_g4/np.tile(np.reshape(energy_g4, (-1, 1, 1, 1)), (1, 1, 10, 10))\n",
    "energy_voxel_gflash = energy_voxel_gflash/np.tile(np.reshape(energy_gflash, (-1, 1, 1, 1)), (1, 1, 10, 10))\n",
    "\n",
    "\n",
    "shifter_energy_fullrange_g4 = np.mean(energy_g4, 0)\n",
    "shifter_energy_fullrange_gflash = np.mean(energy_gflash, 0)\n",
    "scaler_energy_fullrange_g4 = np.std(energy_g4)\n",
    "scaler_energy_fullrange_gflash = np.std(energy_gflash, 0)\n",
    "\n",
    "\n",
    "\n",
    "energy_g4 = energy_g4/energy_particle_g4\n",
    "energy_gflash = energy_gflash/energy_particle_gflash\n",
    "\n",
    "\n",
    "shifter_g4 = np.mean(energy_voxel_g4, 0)\n",
    "shifter_gflash = np.mean(energy_voxel_gflash, 0)\n",
    "scaler_g4 = np.std(energy_voxel_g4, 0)\n",
    "scaler_gflash = np.std(energy_voxel_gflash, 0)\n",
    "\n",
    "energy_voxel_g4 = (energy_voxel_g4 - shifter_g4)/scaler_g4\n",
    "energy_voxel_gflash = (energy_voxel_gflash - shifter_gflash)/scaler_gflash\n",
    "\n",
    "\n",
    "\n",
    "shifter_energy_g4 = np.mean(energy_g4, 0)\n",
    "shifter_energy_gflash = np.mean(energy_gflash, 0)\n",
    "scaler_energy_g4 = np.std(energy_g4)\n",
    "scaler_energy_gflash = np.std(energy_gflash, 0)\n",
    "\n",
    "energy_g4 = (energy_g4 - shifter_energy_g4)/scaler_energy_g4\n",
    "energy_gflash = (energy_gflash - shifter_energy_gflash)/scaler_energy_gflash\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 10000\n",
    "\n",
    "\n",
    "npar = int(energy_voxel_g4.shape[0])\n",
    "\n",
    "            \n",
    "X_init = energy_voxel_gflash\n",
    "Y_init = np.concatenate((energy_gflash, energy_g4, energy_particle_gflash), 1)\n",
    "init_sample = torch.tensor(X_init).view(X_init.shape[0], 1, 10, 10)\n",
    "init_lable = torch.tensor(Y_init)\n",
    "scaling_factor = 7\n",
    "#init_sample = (init_sample - init_sample.mean()) / init_sample.std() * scaling_factor\n",
    "init_ds = TensorDataset(init_sample, init_lable)\n",
    "init_dl = DataLoader(init_ds, batch_size=batch_size, shuffle=False)\n",
    "#init_dl = repeater(init_dl)\n",
    "print(init_sample.shape)\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "X_final = energy_voxel_g4\n",
    "Y_final = np.concatenate((energy_g4, energy_gflash, energy_particle_g4), 1)\n",
    "scaling_factor = 7.\n",
    "final_sample = torch.tensor(X_final).view(X_final.shape[0], 1, 10, 10)\n",
    "final_label = torch.tensor(Y_final)\n",
    "#final_sample = (final_sample - final_sample.mean()) / final_sample.std() * scaling_factor\n",
    "final_ds = TensorDataset(final_sample, final_label)\n",
    "final_dl = DataLoader(final_ds, batch_size=batch_size, shuffle=False)\n",
    "#final_dl = repeater(final_dl)\n",
    "\n",
    "#mean_final = torch.tensor(0.)\n",
    "#var_final = torch.tensor(1.*10**3) #infty like\n",
    "\n",
    "mean_final = torch.zeros(1, 10, 10).to(device)\n",
    "var_final = 1.*torch.ones(1, 10, 10).to(device)\n",
    "\n",
    "print(final_sample.shape)\n",
    "print(mean_final.shape)\n",
    "print(var_final.shape)\n",
    "\n",
    "\n",
    "dls = {'f': init_dl, 'b': final_dl}\n",
    "\n",
    "d = init_sample[0].shape  # shape of object to diffuse\n",
    "dy = init_lable[0].shape  # shape of object to diffuse\n",
    "de = [1]  # shape of object to diffuse\n",
    "\n",
    "\n",
    "\n",
    "lr = 1e-5\n",
    "\n",
    "\n",
    "num_steps_voxel = 20\n",
    "gamma_max_voxel = 0.001\n",
    "gamma_min_voxel = 0.001\n",
    "\n",
    "n = num_steps_voxel//2\n",
    "gamma_half_voxel = np.linspace(gamma_min_voxel, gamma_max_voxel, n)\n",
    "gammas_voxel = np.concatenate([gamma_half_voxel, np.flip(gamma_half_voxel)])\n",
    "gammas_voxel = torch.tensor(gammas_voxel).to(device)\n",
    "T_voxel = torch.sum(gammas_voxel)\n",
    "\n",
    "print(gammas_voxel)\n",
    "\n",
    "\n",
    "\n",
    "num_steps_energy = 20\n",
    "gamma_max_energy = 0.001\n",
    "gamma_min_energy = 0.001\n",
    "\n",
    "n = num_steps_energy//2\n",
    "gamma_half_energy = np.linspace(gamma_min_energy, gamma_max_energy, n)\n",
    "gammas_energy = np.concatenate([gamma_half_energy, np.flip(gamma_half_energy)])\n",
    "gammas_energy = torch.tensor(gammas_energy).to(device)\n",
    "T_energy = torch.sum(gammas_energy)\n",
    "\n",
    "print(gammas_energy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## decay=1.0: No change on update\n",
    "## decay=0.0: No memory of previous updates, memory is euqal to last update\n",
    "## decay=0.9: New value 9 parts previous updates, 1 part current update\n",
    "## decay=0.95: New value 49 parts previous updates, 1 part current update\n",
    "\n",
    "modelEnergy_f = ScoreNetworkEnergy(n_cond = 1).to(device)\n",
    "modelEnergy_b = ScoreNetworkEnergy(n_cond = 1).to(device)\n",
    "\n",
    "modelEnergy_f = torch.nn.DataParallel(modelEnergy_f)\n",
    "modelEnergy_b = torch.nn.DataParallel(modelEnergy_b)\n",
    "\n",
    "netEnergy_f = EMA(model=modelEnergy_f, decay=0.95).to(device)\n",
    "netEnergy_b = EMA(model=modelEnergy_b, decay=0.95).to(device)\n",
    "\n",
    "netsEnergy  = {'f': netEnergy_f, 'b': netEnergy_b }\n",
    "\n",
    "\n",
    "netsEnergy['f'].load_state_dict(torch.load('./models/Iter13_net_f_GFlash_Energy.pth', map_location=device))\n",
    "netsEnergy['b'].load_state_dict(torch.load('./models/Iter13_net_b_GFlash_Energy.pth', map_location=device))\n",
    "\n",
    "\n",
    "netsEnergy['f'].eval()\n",
    "netsEnergy['b'].eval()\n",
    "\n",
    "\n",
    "modelConv_f = ScoreNetworkConv(n_cond = init_lable.size(1)).to(device)\n",
    "modelConv_b = ScoreNetworkConv(n_cond = init_lable.size(1)).to(device)\n",
    "\n",
    "modelConv_f = torch.nn.DataParallel(modelConv_f)\n",
    "modelConv_b = torch.nn.DataParallel(modelConv_b)\n",
    "\n",
    "\n",
    "netConv_f = EMA(model=modelConv_f, decay=0.95).to(device)\n",
    "netConv_b = EMA(model=modelConv_b, decay=0.95).to(device)\n",
    "\n",
    "netsConv  = {'f': netConv_f, 'b': netConv_b }\n",
    "\n",
    "netsConv['f'].load_state_dict(torch.load('./models/Iter14_net_f_GFlash_Conv.pth', map_location=device))\n",
    "netsConv['b'].load_state_dict(torch.load('./models/Iter14_net_b_GFlash_Conv.pth', map_location=device))\n",
    "\n",
    "netsConv['f'].eval()\n",
    "netsConv['b'].eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd78d12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample (forward_or_backward = 'f', forward_or_backward_rev = 'b'):\n",
    "    data_orig = []\n",
    "    data_energy_particle = []\n",
    "    data_x = []\n",
    "    data_y = []\n",
    "    iteration = -1\n",
    "\n",
    "    for b, dat in enumerate(dls[forward_or_backward]):    \n",
    "        x, y = dat\n",
    "        x = x.float().to(device)\n",
    "        y = y.float().to(device)\n",
    "        \n",
    "        \n",
    "        x_orig = x.clone()\n",
    "\n",
    "        N = x.shape[0]\n",
    "        \n",
    "        #gammas_new = gammas.reshape((1, num_steps, 1)).repeat((N, 1, 1))\n",
    "        \n",
    "        \n",
    "        steps_voxel = torch.arange(num_steps_voxel).to(device)\n",
    "        time_voxel = torch.cumsum(gammas_voxel, 0).to(device).float()\n",
    "        steps_voxel = steps_voxel.reshape((1, num_steps_voxel, 1)).repeat((N, 1, 1))\n",
    "        time_voxel = time_voxel.reshape((1, num_steps_voxel, 1)).repeat((N, 1, 1))\n",
    "        steps_voxel = time_voxel\n",
    "        num_iter_voxel = num_steps_voxel\n",
    "\n",
    "        steps_energy = torch.arange(num_steps_energy).to(device)\n",
    "        time_energy = torch.cumsum(gammas_energy, 0).to(device).float()\n",
    "        steps_energy = steps_energy.reshape((1, num_steps_energy, 1)).repeat((N, 1, 1))\n",
    "        time_energy = time_energy.reshape((1, num_steps_energy, 1)).repeat((N, 1, 1))\n",
    "        steps_energy = time_energy\n",
    "        num_iter_energy = num_steps_energy\n",
    "\n",
    "        energy__shower_tot = torch.Tensor(N, num_steps_energy, *de).to(x.device)\n",
    "        energy__shower_out = torch.Tensor(N, num_steps_energy, *de).to(x.device)\n",
    "        \n",
    "        x_tot = torch.Tensor(N, num_steps_voxel, *d).to(x.device)\n",
    "        out = torch.Tensor(N, num_steps_voxel, *d).to(x.device)\n",
    "        \n",
    "        #store_steps = steps\n",
    "        #steps_expanded = time\n",
    "        \n",
    "        \n",
    "        shifter_energy_g4_tensor = torch.tensor(shifter_energy_g4).to(x.device)\n",
    "        shifter_energy_gflash_tensor = torch.tensor(shifter_energy_gflash).to(x.device)\n",
    "        scaler_energy_g4_tensor = torch.tensor(scaler_energy_g4).to(x.device)\n",
    "        scaler_energy_gflash_tensor = torch.tensor(scaler_energy_gflash).to(x.device)\n",
    "        \n",
    "        shifter_energy_fullrange_g4_tensor = torch.tensor(shifter_energy_fullrange_g4).to(x.device)\n",
    "        shifter_energy_fullrange_gflash_tensor = torch.tensor(shifter_energy_fullrange_gflash).to(x.device)\n",
    "        scaler_energy_fullrange_g4_tensor = torch.tensor(scaler_energy_fullrange_g4).to(x.device)\n",
    "        scaler_energy_fullrange_gflash_tensor = torch.tensor(scaler_energy_fullrange_gflash).to(x.device)\n",
    "        \n",
    "        shifter_g4_tensor = torch.tensor(shifter_g4).to(x.device)\n",
    "        shifter_gflash_tensor = torch.tensor(shifter_gflash).to(x.device)\n",
    "        scaler_g4_tensor = torch.tensor(scaler_g4).to(x.device)\n",
    "        scaler_gflash_tensor = torch.tensor(scaler_gflash).to(x.device)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        y_current = y.clone()\n",
    "        energy__shower_start = y_current[:,0:1].clone()\n",
    "        energy__shower_target = y_current[:,1:2].clone()\n",
    "        energy__particle = y_current[:,2:3].clone()\n",
    "\n",
    "        \n",
    "        energy__shower_orig = energy__shower_start.clone().view(-1, 1, 1, 1)\n",
    "\n",
    "        energy__shower_orig = (energy__shower_orig * scaler_energy_gflash_tensor) + shifter_energy_gflash_tensor\n",
    "        energy__shower_orig = energy__shower_orig * energy__particle.view(-1, 1, 1, 1)\n",
    "\n",
    "        #print(energy__shower_orig)\n",
    "                            \n",
    "        with torch.no_grad():\n",
    "            for k in range(num_iter_energy):\n",
    "                gamma = gammas_energy[k]\n",
    "                \n",
    "                t_old = energy__shower_start + netsEnergy[forward_or_backward_rev](energy__shower_start, \n",
    "                                                                             steps_energy[:, k, :],\n",
    "                                                                             energy__particle, energy__shower_start)\n",
    "\n",
    "                                                \n",
    "                if k == num_iter_energy-1:\n",
    "                    energy__shower_start = t_old\n",
    "                else:\n",
    "                    z = torch.randn(energy__shower_start.shape, device=x.device)\n",
    "                    energy__shower_start = t_old + torch.sqrt(2 * gamma) * z\n",
    "                \n",
    "                t_new = energy__shower_start + netsEnergy[forward_or_backward_rev](energy__shower_start, \n",
    "                                                                             steps_energy[:, k, :],\n",
    "                                                                             energy__particle, energy__shower_start)\n",
    "                \n",
    "\n",
    "                energy__shower_tot[:, k, :] = energy__shower_start\n",
    "                energy__shower_out[:, k, :] = (t_old - t_new)\n",
    "               \n",
    "            \n",
    "        energy__shower_tot = (energy__shower_tot * scaler_energy_g4_tensor) + shifter_energy_g4_tensor\n",
    "        energy__shower_tot = energy__shower_tot * energy__particle.view(-1, 1, 1)\n",
    "        energy__shower_tot = (energy__shower_tot - shifter_energy_fullrange_g4_tensor) / scaler_energy_fullrange_g4_tensor\n",
    "            \n",
    "        energy__shower_start = (energy__shower_start * scaler_energy_gflash_tensor) + shifter_energy_gflash_tensor\n",
    "        energy__shower_start = energy__shower_start * energy__particle.view(-1, 1)\n",
    "            \n",
    "        y_current[:,1:2] = energy__shower_tot[:, iteration]\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for k in range(num_iter_voxel):\n",
    "                gamma = gammas_voxel[k]\n",
    "                t_old = x + netsConv[forward_or_backward_rev](x, steps_voxel[:, k, :], y_current, x)\n",
    "\n",
    "                if k == num_iter_voxel-1:\n",
    "                    x = t_old\n",
    "                else:\n",
    "                    z = torch.randn(x.shape, device=x.device)\n",
    "                    x = t_old + torch.sqrt(2 * gamma) * z\n",
    "                    \n",
    "                #x = t_old\n",
    "\n",
    "                t_new = x + netsConv[forward_or_backward_rev](x, steps_voxel[:, k, :], y_current,x )\n",
    "\n",
    "                x_tot[:, k, :] = x\n",
    "                out[:, k, :] = (t_old - t_new)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        x_orig = x_orig * scaler_gflash_tensor + shifter_gflash_tensor\n",
    "        x_orig = x_orig * energy__shower_orig\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        #print(energy__shower_orig)\n",
    "        \n",
    "        energy__shower_tot = (energy__shower_tot * scaler_energy_fullrange_g4_tensor) + shifter_energy_fullrange_g4_tensor\n",
    "        #print(energy__shower_tot)\n",
    "\n",
    "        \n",
    "        x_tot = (x_tot * scaler_g4_tensor) + shifter_g4_tensor\n",
    "\n",
    "        \n",
    "        \n",
    "        sum_old = torch.sum(x_tot, (2,3,4)).view(-1, x_tot.size(1), 1, 1, 1)\n",
    "        sum_new = energy__shower_tot[:,iteration].view(-1, 1, 1, 1, 1)\n",
    "        \n",
    "        x_tot = x_tot / sum_old * sum_new\n",
    "\n",
    "        #print(sum_old.shape)\n",
    "\n",
    "        #print(sum_new)\n",
    "        #print(x_orig.shape)\n",
    "        \n",
    "        y_current[:,1:2] = energy__shower_tot[:, iteration]\n",
    "        y_current[:,0:1] = energy__shower_start\n",
    "\n",
    "        \n",
    "        data_orig.append(x_orig.cpu().numpy())\n",
    "        data_x.append(x_tot.cpu().numpy())\n",
    "        data_y.append(y_current.cpu().numpy())\n",
    "        \n",
    "        data_energy_particle.append(energy__particle.cpu().numpy()*10.0)\n",
    "        \n",
    "        \n",
    "\n",
    "    return(np.concatenate(data_orig, 0), np.concatenate(data_x, 0), \n",
    "           np.concatenate(data_y, 0), np.concatenate(data_energy_particle, 0))\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c07e7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "energy_voxel_gflash_orig, energy_voxel_gflash_trafo, energy_gflash_trafo, energy_particle = sample(forward_or_backward = 'f', forward_or_backward_rev = 'b')\n",
    "\n",
    "\n",
    "cutOff = 0.0\n",
    "\n",
    "data_trafo = energy_voxel_gflash_trafo[:,-1]#*100\n",
    "\n",
    "data_orig = energy_voxel_gflash_orig\n",
    "data_full = np.load(file_path_g4 + 'full.npy')\n",
    "\n",
    "\n",
    "data_full[data_full<0] = 0.0\n",
    "data_orig[data_orig<0] = 0.0\n",
    "data_trafo[data_trafo<0] = 0.0\n",
    "\n",
    "weight_dict = {\n",
    "    'Geant4': np.ones(data_full.shape[0]),\n",
    "    'GFlash': np.ones(data_full.shape[0]),\n",
    "    'SQuIRELS': np.ones(data_full.shape[0]),\n",
    "    'SQuIRELS-E': np.ones(data_full.shape[0]),\n",
    "}\n",
    "triangle=True\n",
    "\n",
    "y_lim_ratio_l = {'esum': [0.9, 1.1],\n",
    "                 'esumfrac': [0.0, 2.0],\n",
    "                 'emax': [0.0, 2.0],\n",
    "                 'nhit': [0.0, 2.0],\n",
    "                 'espec': [0.0, 2.0],\n",
    "                 'ex': [0.0, 2.0],\n",
    "                }\n",
    "    \n",
    "binning_l = {'esum': np.linspace(5,105,50),\n",
    "             'esumfrac': np.linspace(0.97,1.01,50),\n",
    "             'emax': np.linspace(0, 27,50),\n",
    "             'nhit': np.linspace(0, 100,101),\n",
    "             'espec': np.logspace(-4, 1.5, 100),\n",
    "             'ex': np.linspace(0, 10,11),\n",
    "            }\n",
    "\n",
    "y_range_l = {'esum': None,\n",
    "             'esumfrac': None,\n",
    "             'emax': None,\n",
    "             'nhit': None,\n",
    "             'espec': [1e-6, 1e3],\n",
    "             'ex': [8e-3, 5e2],\n",
    "            }\n",
    "\n",
    "\n",
    "\n",
    "print(data_full.shape)\n",
    "\n",
    "### Esum 1D ###\n",
    "feed_dict = {\n",
    "    'Geant4': np.sum(data_full[:,:100],(1)),\n",
    "    'GFlash': np.sum(data_orig,(1,2,3)),\n",
    "    'SQuIRELS-E': energy_gflash_trafo[:,1],\n",
    "}\n",
    "\n",
    "fig,ax0 = HistRoutine(feed_dict,weights = weight_dict,\n",
    "                            label_loc= 'best',\n",
    "                            xlabel='Total Energy Sum [GeV]', ylabel= 'Normalized entries',\n",
    "                            binning = binning_l['esum'],triangle=triangle,\n",
    "                            logy=False, reference_name='Geant4', y_lim_ratio = y_lim_ratio_l['esum'],\n",
    "                            title='10-100 GeV', y_range= y_range_l['esum'])\n",
    "fig.savefig('./plots/esum_1D.pdf')\n",
    "\n",
    "\n",
    "\n",
    "### Esum 1D ###\n",
    "feed_dict = {\n",
    "    'Geant4': np.sum(data_full[:,:100],(1))/(data_full[:,200]/1000.0),\n",
    "    'GFlash': np.sum(data_orig,(1,2,3))/energy_particle[:,0],\n",
    "    'SQuIRELS-E': energy_gflash_trafo[:,1]/energy_particle[:,0],\n",
    "}\n",
    "\n",
    "fig,ax0 = HistRoutine(feed_dict,weights = weight_dict,\n",
    "                            label_loc= 'best',\n",
    "                            xlabel='$E_{shower}/E_{particle}$', ylabel= 'Normalized entries',\n",
    "                            binning = binning_l['esumfrac'],triangle=triangle,\n",
    "                            logy=False, reference_name='Geant4', y_lim_ratio = y_lim_ratio_l['esumfrac'],\n",
    "                            title='10-100 GeV', y_range= y_range_l['esumfrac'])\n",
    "fig.savefig('./plots/esumfrac_1D.pdf')\n",
    "\n",
    "\n",
    "\n",
    "### Esum ###\n",
    "feed_dict = {\n",
    "    'Geant4': np.sum(data_full[:,:100],(1)),\n",
    "    'GFlash': np.sum(data_orig,(1,2,3)),\n",
    "    'SQuIRELS': np.sum(data_trafo,(1,2,3)),\n",
    "}\n",
    "\n",
    "fig,ax0 = HistRoutine(feed_dict,weights = weight_dict,\n",
    "                            label_loc= 'best',\n",
    "                            xlabel='Total Energy Sum [GeV]', ylabel= 'Normalized entries',\n",
    "                            binning = binning_l['esum'],triangle=triangle,\n",
    "                            logy=False, reference_name='Geant4', y_lim_ratio = y_lim_ratio_l['esum'],\n",
    "                            title='10-100 GeV', y_range= y_range_l['esum'])\n",
    "#ax0.set_xscale(\"log\")\n",
    "fig.savefig('./plots/esum.pdf')\n",
    "\n",
    "\n",
    "### emax ###\n",
    "feed_dict = {\n",
    "    'Geant4': np.max(data_full[:,:100],(1)),\n",
    "    'GFlash': np.max(data_orig,(1,2,3)),\n",
    "    'SQuIRELS': np.max(data_trafo,(1,2,3)),\n",
    "}\n",
    "\n",
    "fig,ax0 = HistRoutine(feed_dict,weights = weight_dict,\n",
    "                            label_loc= 'best',\n",
    "                            xlabel='Brightest Cell Energy [GeV]', ylabel= 'Normalized entries',\n",
    "                            binning = binning_l['emax'],triangle=triangle,\n",
    "                            logy=False, reference_name='Geant4', y_lim_ratio = y_lim_ratio_l['emax'],\n",
    "                            title='10-100 GeV', y_range= y_range_l['emax'])\n",
    "#ax0.set_xscale(\"log\")\n",
    "fig.savefig('./plots/emax.pdf')\n",
    "\n",
    "\n",
    "### nhit ###\n",
    "def get_nhit(x):\n",
    "    temp = np.array(x)\n",
    "    temp = np.array(x)\n",
    "    temp[temp>1e-3] = 1\n",
    "    temp[temp<=1e-3] = 0\n",
    "    return temp\n",
    "\n",
    "\n",
    "feed_dict = {\n",
    "    'Geant4': np.sum(get_nhit(data_full[:,:100]),(1)),\n",
    "    'GFlash': np.sum(get_nhit(data_orig),(1,2,3)),\n",
    "    'SQuIRELS': np.sum(get_nhit(data_trafo),(1,2,3)),\n",
    "}\n",
    "\n",
    "fig,ax0 = HistRoutine(feed_dict,weights = weight_dict,\n",
    "                            label_loc= 'best',\n",
    "                            xlabel='# of hits above 1MeV', ylabel= 'Normalized entries',\n",
    "                            binning = binning_l['nhit'],triangle=triangle,\n",
    "                            logy=False, reference_name='Geant4', y_lim_ratio = y_lim_ratio_l['nhit'],\n",
    "                            title='10-100 GeV', y_range= y_range_l['nhit'])\n",
    "#ax0.set_xscale(\"log\")\n",
    "fig.savefig('./plots/nhit.pdf')\n",
    "\n",
    "\n",
    "### espec ###\n",
    "feed_dict = {\n",
    "    'Geant4': np.reshape(data_full[:,:100], -1),\n",
    "    'GFlash': np.reshape(data_orig, -1),\n",
    "    'SQuIRELS': np.reshape(data_trafo, -1),\n",
    "}\n",
    "\n",
    "weight_dict = {\n",
    "    'Geant4': np.ones(np.reshape(data_full[:,:100], -1).shape[0]),\n",
    "    'GFlash': np.ones(np.reshape(data_full[:,:100], -1).shape[0]),\n",
    "    'SQuIRELS': np.ones(np.reshape(data_full[:,:100], -1).shape[0]),\n",
    "}\n",
    "\n",
    "fig,ax0 = HistRoutine(feed_dict,weights = weight_dict,\n",
    "                            label_loc= 'best',\n",
    "                            xlabel='Cell Energies [GeV]', ylabel= 'Normalized entries',\n",
    "                            binning = binning_l['espec'], \n",
    "                            logy=True, reference_name='Geant4', y_lim_ratio = y_lim_ratio_l['espec'],\n",
    "                            title='10-100 GeV', triangle=triangle, y_range= y_range_l['espec'])\n",
    "ax0.set_xscale(\"log\")\n",
    "fig.savefig('./plots/espec.pdf')\n",
    "\n",
    "\n",
    "### espec_norm ###\n",
    "feed_dict = {\n",
    "    'Geant4': np.reshape(data_full[:,:100], -1),\n",
    "    'GFlash': np.reshape(data_orig, -1),\n",
    "    'SQuIRELS': np.reshape(data_trafo, -1),\n",
    "}\n",
    "\n",
    "weight_dict = {\n",
    "    'Geant4': np.ones(np.reshape(data_full[:,:100], -1).shape[0])/np.reshape(data_full[:,:100], -1).shape[0],\n",
    "    'GFlash': np.ones(np.reshape(data_full[:,:100], -1).shape[0])/np.reshape(data_full[:,:100], -1).shape[0],\n",
    "    'SQuIRELS': np.ones(np.reshape(data_full[:,:100], -1).shape[0])/np.reshape(data_full[:,:100], -1).shape[0],\n",
    "}\n",
    "\n",
    "\n",
    "fig,ax0 = HistRoutine(feed_dict,weights = weight_dict,\n",
    "                            label_loc= 'best', density=False,\n",
    "                            xlabel='Cell Energies', ylabel= 'Normalized entries',\n",
    "                            binning = binning_l['espec'], \n",
    "                            logy=True, reference_name='Geant4', y_lim_ratio = y_lim_ratio_l['espec'],\n",
    "                            title='10-100 GeV', triangle=triangle, y_range= y_range_l['espec'])\n",
    "ax0.set_xscale(\"log\")\n",
    "fig.savefig('./plots/espec_norm.pdf')\n",
    "\n",
    "### ex ###\n",
    "weight_dict = {\n",
    "    'Geant4': np.reshape(np.sum(np.reshape(data_full[:,:100], (-1, 10, 10)), 2), -1)/data_full.shape[0],\n",
    "    'GFlash': np.reshape(np.sum(np.reshape(data_orig, (-1, 10, 10)), 2), -1)/data_full.shape[0],\n",
    "    'SQuIRELS': np.reshape(np.sum(np.reshape(data_trafo, (-1, 10, 10)), 2), -1)/data_full.shape[0],\n",
    "}\n",
    "\n",
    "feed_dict = {\n",
    "    'Geant4': np.tile(np.arange(0.5, 9.6, 1), data_full.shape[0]),\n",
    "    'GFlash': np.tile(np.arange(0.5, 9.6, 1), data_full.shape[0]),\n",
    "    'SQuIRELS': np.tile(np.arange(0.5, 9.6, 1), data_full.shape[0]),\n",
    "}\n",
    "\n",
    "print(feed_dict['Geant4'].shape)\n",
    "\n",
    "\n",
    "fig,ax0 = HistRoutine(feed_dict,weights = weight_dict,\n",
    "                            label_loc= 'best', density=False,\n",
    "                            xlabel='x Profile', ylabel= 'Mean Energy [GeV]',\n",
    "                            binning = binning_l['ex'],triangle=triangle,\n",
    "                            logy=True, reference_name='Geant4', y_lim_ratio = y_lim_ratio_l['ex'],\n",
    "                            title='10-100 GeV', y_range= y_range_l['ex'])\n",
    "#ax0.set_xscale(\"log\")\n",
    "fig.savefig('./plots/ex.pdf')\n",
    "\n",
    "### ey ###\n",
    "weight_dict = {\n",
    "    'Geant4': np.reshape(np.sum(np.reshape(data_full[:,:100], (-1, 10, 10)), 1), -1)/data_full.shape[0],\n",
    "    'GFlash': np.reshape(np.sum(np.reshape(data_orig, (-1, 10, 10)), 1), -1)/data_full.shape[0],\n",
    "    'SQuIRELS': np.reshape(np.sum(np.reshape(data_trafo, (-1, 10, 10)), 1), -1)/data_full.shape[0],\n",
    "}\n",
    "\n",
    "feed_dict = {\n",
    "    'Geant4': np.tile(np.arange(0.5, 9.6, 1), data_full.shape[0]),\n",
    "    'GFlash': np.tile(np.arange(0.5, 9.6, 1), data_full.shape[0]),\n",
    "    'SQuIRELS': np.tile(np.arange(0.5, 9.6, 1), data_full.shape[0]),\n",
    "}\n",
    "\n",
    "print(feed_dict['Geant4'].shape)\n",
    "\n",
    "\n",
    "fig,ax0 = HistRoutine(feed_dict,weights = weight_dict,\n",
    "                            label_loc= 'best', density=False,\n",
    "                            xlabel='y Profile', ylabel= 'Mean Energy [GeV]',\n",
    "                            binning = binning_l['ex'],triangle=triangle,\n",
    "                            logy=True, reference_name='Geant4', y_lim_ratio = y_lim_ratio_l['ex'],\n",
    "                            title='10-100 GeV', y_range= y_range_l['ex'])\n",
    "#ax0.set_xscale(\"log\")\n",
    "fig.savefig('./plots/ey.pdf')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig,ax0 = ScatterRoutine(xdata=energy_gflash_trafo[:10000,0], ydata=energy_gflash_trafo[:10000,1], \n",
    "                         data_label = 'SQuIRELS-E',\n",
    "                         xlabel='$e_{GF}$',ylabel='$e_{refined}$',\n",
    "                         label_loc='best', title='10-100 GeV')\n",
    "fig.savefig('./plots/scatter.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06589857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff75a9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "shower_dict = {}\n",
    "for energy in [20, 50, 80]:\n",
    "\n",
    "\n",
    "    \n",
    "    file_path_gflash = './data/run_GFlash01_100k_{:d}GeV_eval_full'.format(energy)\n",
    "    file_path_g4 = './data/run_Geant_100k_{:d}GeV_eval_full'.format(energy)\n",
    "    file_name = '.npy'\n",
    "\n",
    "    energy_voxel_g4 = np.load(file_path_g4 + file_name)[:, 0:100].astype(np.float32)\n",
    "    energy_voxel_gflash  = np.load(file_path_gflash + file_name)[:, 0:100].astype(np.float32)\n",
    "\n",
    "\n",
    "    energy_particle_g4 = np.load(file_path_g4 + file_name)[:, 200:201].astype(np.float32)/10000.0\n",
    "    energy_particle_gflash  = np.load(file_path_gflash + file_name)[:, 200:201].astype(np.float32)/10000.0\n",
    "\n",
    "    if energy_particle_gflash.shape[1] == 0:\n",
    "        energy_particle_g4 = np.ones((energy_voxel_g4.shape[0], 1)).astype(np.float32)/10000.0*50000.0\n",
    "        energy_particle_gflash  = np.ones((energy_particle_gflash.shape[0], 1)).astype(np.float32)/10000.0*50000.0\n",
    "\n",
    "\n",
    "    energy_g4 = np.sum(energy_voxel_g4, 1, keepdims=True)\n",
    "    energy_gflash = np.sum(energy_voxel_gflash, 1, keepdims=True)\n",
    "\n",
    "\n",
    "    energy_voxel_g4 = np.reshape(energy_voxel_g4, (-1, 1, 10, 10))\n",
    "    energy_voxel_gflash = np.reshape(energy_voxel_gflash, (-1, 1, 10, 10))\n",
    "\n",
    "\n",
    "    energy_voxel_g4 = energy_voxel_g4/np.tile(np.reshape(energy_g4, (-1, 1, 1, 1)), (1, 1, 10, 10))\n",
    "    energy_voxel_gflash = energy_voxel_gflash/np.tile(np.reshape(energy_gflash, (-1, 1, 1, 1)), (1, 1, 10, 10))\n",
    "\n",
    "    energy_g4 = energy_g4/energy_particle_g4\n",
    "    energy_gflash = energy_gflash/energy_particle_gflash\n",
    "\n",
    "\n",
    "\n",
    "    energy_voxel_g4 = (energy_voxel_g4 - shifter_g4)/scaler_g4\n",
    "    energy_voxel_gflash = (energy_voxel_gflash - shifter_gflash)/scaler_gflash\n",
    "\n",
    "    energy_g4 = (energy_g4 - shifter_energy_g4)/scaler_energy_g4\n",
    "    energy_gflash = (energy_gflash - shifter_energy_gflash)/scaler_energy_gflash\n",
    "\n",
    "\n",
    "\n",
    "    batch_size = 25000\n",
    "\n",
    "\n",
    "    npar = int(energy_voxel_g4.shape[0])\n",
    "\n",
    "\n",
    "    X_init = energy_voxel_gflash\n",
    "    Y_init = np.concatenate((energy_gflash, energy_g4, energy_particle_gflash), 1)\n",
    "    init_sample = torch.tensor(X_init).view(X_init.shape[0], 1, 10, 10)\n",
    "    init_lable = torch.tensor(Y_init)\n",
    "    scaling_factor = 7\n",
    "    #init_sample = (init_sample - init_sample.mean()) / init_sample.std() * scaling_factor\n",
    "    init_ds = TensorDataset(init_sample, init_lable)\n",
    "    init_dl = DataLoader(init_ds, batch_size=batch_size, shuffle=False)\n",
    "    #init_dl = repeater(init_dl)\n",
    "    print(init_sample.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    X_final = energy_voxel_g4\n",
    "    Y_final = np.concatenate((energy_g4, energy_gflash, energy_particle_g4), 1)\n",
    "    scaling_factor = 7.\n",
    "    final_sample = torch.tensor(X_final).view(X_final.shape[0], 1, 10, 10)\n",
    "    final_label = torch.tensor(Y_final)\n",
    "    #final_sample = (final_sample - final_sample.mean()) / final_sample.std() * scaling_factor\n",
    "    final_ds = TensorDataset(final_sample, final_label)\n",
    "    final_dl = DataLoader(final_ds, batch_size=batch_size, shuffle=False)\n",
    "    #final_dl = repeater(final_dl)\n",
    "\n",
    "    dls = {'f': init_dl, 'b': final_dl}\n",
    "\n",
    "\n",
    "\n",
    "    #energy_voxel_gflash_orig, energy_voxel_gflash_trafo, energy_gflash_trafo, _ = sample(forward_or_backward = 'f', forward_or_backward_rev = 'b')\n",
    "    energy_voxel_gflash_orig, energy_voxel_gflash_trafo, energy_gflash_trafo, energy_particle = sample(forward_or_backward = 'f', forward_or_backward_rev = 'b')\n",
    "\n",
    "    \n",
    "    data_trafo = energy_voxel_gflash_trafo[:,-1]#*100\n",
    "\n",
    "    data_orig = energy_voxel_gflash_orig\n",
    "    data_full = np.load(file_path_g4 + 'full.npy')\n",
    "\n",
    "    data_full[data_full<0] = 0.0\n",
    "    data_orig[data_orig<0] = 0.0\n",
    "    data_trafo[data_trafo<0] = 0.0\n",
    "    \n",
    "    shower_dict[energy] = [data_full, data_orig, data_trafo, energy_gflash_trafo]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61108614",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for energy in [20, 50, 80]:\n",
    "\n",
    "    [data_full, data_orig, data_trafo, energy_gflash_trafo] = shower_dict[energy]\n",
    "\n",
    "    \n",
    "    weight_dict = {\n",
    "        'Geant4': np.ones(data_full.shape[0]),\n",
    "        'GFlash': np.ones(data_full.shape[0]),\n",
    "        'SQuIRELS': np.ones(data_full.shape[0]),\n",
    "        'SQuIRELS-E': np.ones(data_full.shape[0]),\n",
    "    }\n",
    "    triangle=True\n",
    "\n",
    "    y_lim_ratio_l = {'esum': [0.0, 2.0],\n",
    "                     'emax': [0.0, 2.0],\n",
    "                     'nhit': [0.0, 2.0],\n",
    "                     'espec': [0.0, 2.0],\n",
    "                     'ex': [0.0, 2.0],\n",
    "                    }\n",
    "    \n",
    "    y_range_l = {'esum_20': None,\n",
    "                 'esum_50': None,\n",
    "                 'esum_80': None,\n",
    "                 'emax_20': None,\n",
    "                 'emax_50': None,\n",
    "                 'emax_80': None,\n",
    "                 'nhit_20': None,\n",
    "                 'nhit_50': None,\n",
    "                 'nhit_80': None,\n",
    "                 'espec': [1e-6, 1e5],\n",
    "                 'ex': [8e-3, 5e2],\n",
    "            }\n",
    "\n",
    "\n",
    "\n",
    "    binning_l = {'esum_20': np.linspace(19.5,20.1,50),\n",
    "                 'esum_50': np.linspace(48.5,50.1,50),\n",
    "                 'esum_80': np.linspace(77.5,80.1,50),\n",
    "                 'emax_20': np.linspace(4.5, 6.5,50),\n",
    "                 'emax_50': np.linspace(11,15,50),\n",
    "                 'emax_80': np.linspace(18.5,22,50),\n",
    "                 'nhit_20': np.linspace(0, 100,101),\n",
    "                 'nhit_50': np.linspace(0, 100,101),\n",
    "                 'nhit_80': np.linspace(0, 100,101),\n",
    "                 'espec': np.logspace(-4, 1.5, 100),\n",
    "                 'ex': np.linspace(0, 10,11),\n",
    "                }\n",
    "\n",
    "    print(data_full.shape)\n",
    "\n",
    "    ### Esum 1d ###\n",
    "    feed_dict = {\n",
    "        'Geant4': np.sum(data_full[:,:100],(1)),\n",
    "        'GFlash': np.sum(data_orig,(1,2,3)),\n",
    "        'SQuIRELS-E': energy_gflash_trafo[:,1],\n",
    "    }\n",
    "\n",
    "    fig,ax0 = HistRoutine(feed_dict,weights = weight_dict,\n",
    "                                label_loc= 'best',\n",
    "                                xlabel='Total Energy Sum [GeV]', ylabel= 'Normalized entries',\n",
    "                                binning = binning_l['esum_{:d}'.format(energy)] ,triangle=triangle,\n",
    "                                logy=False, reference_name='Geant4', y_lim_ratio = y_lim_ratio_l['esum'],\n",
    "                                title='{:d} GeV'.format(energy), y_range= y_range_l['esum_{:d}'.format(energy)])\n",
    "    #ax0.set_xscale(\"log\")\n",
    "    fig.savefig('./plots/esum_1D_{:d}GeV.pdf'.format(energy))\n",
    "\n",
    "    #break\n",
    "    \n",
    "    ### Esum ###\n",
    "    feed_dict = {\n",
    "        'Geant4': np.sum(data_full[:,:100],(1)),\n",
    "        'GFlash': np.sum(data_orig,(1,2,3)),\n",
    "        'SQuIRELS': np.sum(data_trafo,(1,2,3)),\n",
    "    }\n",
    "\n",
    "    fig,ax0 = HistRoutine(feed_dict,weights = weight_dict,\n",
    "                                label_loc= 'best',\n",
    "                                xlabel='Total Energy Sum [GeV]', ylabel= 'Normalized entries',\n",
    "                                binning = binning_l['esum_{:d}'.format(energy)] ,triangle=triangle,\n",
    "                                logy=False, reference_name='Geant4', y_lim_ratio = y_lim_ratio_l['esum'],\n",
    "                                title='{:d} GeV'.format(energy), y_range= y_range_l['esum_{:d}'.format(energy)])\n",
    "    #ax0.set_xscale(\"log\")\n",
    "    fig.savefig('./plots/esum_{:d}GeV.pdf'.format(energy))\n",
    "\n",
    "\n",
    "    ### emax ###\n",
    "    feed_dict = {\n",
    "        'Geant4': np.max(data_full[:,:100],(1)),\n",
    "        'GFlash': np.max(data_orig,(1,2,3)),\n",
    "        'SQuIRELS': np.max(data_trafo,(1,2,3)),\n",
    "    }\n",
    "\n",
    "    fig,ax0 = HistRoutine(feed_dict,weights = weight_dict,\n",
    "                                label_loc= 'best',\n",
    "                                xlabel='Brightest Cell Energy [GeV]', ylabel= 'Normalized entries',\n",
    "                                binning = binning_l['emax_{:d}'.format(energy)],triangle=triangle,\n",
    "                                logy=False, reference_name='Geant4', y_lim_ratio = y_lim_ratio_l['emax'],\n",
    "                                title='{:d} GeV'.format(energy), y_range= y_range_l['emax_{:d}'.format(energy)])\n",
    "    #ax0.set_xscale(\"log\")\n",
    "    fig.savefig('./plots/emax_{:d}GeV.pdf'.format(energy))\n",
    "\n",
    "\n",
    "    ### nhit ###\n",
    "    def get_nhit(x):\n",
    "        temp = np.array(x)\n",
    "        temp = np.array(x)\n",
    "        temp[temp>1e-3] = 1\n",
    "        temp[temp<=1e-3] = 0\n",
    "        return temp\n",
    "\n",
    "\n",
    "    feed_dict = {\n",
    "        'Geant4': np.sum(get_nhit(data_full[:,:100]),(1)),\n",
    "        'GFlash': np.sum(get_nhit(data_orig),(1,2,3)),\n",
    "        'SQuIRELS': np.sum(get_nhit(data_trafo),(1,2,3)),\n",
    "    }\n",
    "\n",
    "    fig,ax0 = HistRoutine(feed_dict,weights = weight_dict,\n",
    "                                label_loc= 'best',\n",
    "                                xlabel='# of hits above 1MeV', ylabel= 'Normalized entries',\n",
    "                                binning = binning_l['nhit_{:d}'.format(energy)],triangle=triangle,\n",
    "                                logy=False, reference_name='Geant4', y_lim_ratio = y_lim_ratio_l['nhit'],\n",
    "                                title='{:d} GeV'.format(energy), y_range= y_range_l['nhit_{:d}'.format(energy)])\n",
    "    #ax0.set_xscale(\"log\")\n",
    "    fig.savefig('./plots/nhit_{:d}GeV.pdf'.format(energy))\n",
    "\n",
    "\n",
    "    ### espec ###\n",
    "    def get_espec(x):\n",
    "        temp = np.array(x)\n",
    "        temp = np.array(x)\n",
    "        temp[temp<1e-4] = 0\n",
    "        return temp\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    feed_dict = {\n",
    "        'Geant4': get_espec(np.reshape(data_full[:,:100], -1)),\n",
    "        'GFlash': get_espec(np.reshape(data_orig, -1)),\n",
    "        'SQuIRELS': get_espec(np.reshape(data_trafo, -1)),\n",
    "    }\n",
    "\n",
    "    weight_dict = {\n",
    "        'Geant4': np.ones(np.reshape(data_full[:,:100], -1).shape[0]),\n",
    "        'GFlash': np.ones(np.reshape(data_full[:,:100], -1).shape[0]),\n",
    "        'SQuIRELS': np.ones(np.reshape(data_full[:,:100], -1).shape[0]),\n",
    "    }\n",
    "\n",
    "    fig,ax0 = HistRoutine(feed_dict,weights = weight_dict,\n",
    "                                label_loc= 'best',\n",
    "                                xlabel='Cell Energies [GeV]', ylabel= 'Normalized entries',\n",
    "                                binning = binning_l['espec'], \n",
    "                                logy=True, reference_name='Geant4', y_lim_ratio = y_lim_ratio_l['espec'],\n",
    "                                title='{:d} GeV'.format(energy), triangle=triangle, y_range= y_range_l['espec'])\n",
    "    ax0.set_xscale(\"log\")\n",
    "    fig.savefig('./plots/espec_{:d}GeV.pdf'.format(energy))\n",
    "\n",
    "    ### ex ###\n",
    "    weight_dict = {\n",
    "        'Geant4': np.reshape(np.sum(np.reshape(data_full[:,:100], (-1, 10, 10)), 2), -1)/data_full.shape[0],\n",
    "        'GFlash': np.reshape(np.sum(np.reshape(data_orig, (-1, 10, 10)), 2), -1)/data_full.shape[0],\n",
    "        'SQuIRELS': np.reshape(np.sum(np.reshape(data_trafo, (-1, 10, 10)), 2), -1)/data_full.shape[0],\n",
    "    }\n",
    "\n",
    "    feed_dict = {\n",
    "        'Geant4': np.tile(np.arange(0.5, 9.6, 1), data_full.shape[0]),\n",
    "        'GFlash': np.tile(np.arange(0.5, 9.6, 1), data_full.shape[0]),\n",
    "        'SQuIRELS': np.tile(np.arange(0.5, 9.6, 1), data_full.shape[0]),\n",
    "    }\n",
    "    \n",
    "    \n",
    "    fig,ax0 = HistRoutine(feed_dict,weights = weight_dict,\n",
    "                                label_loc= 'best', density=False,\n",
    "                                xlabel='x Profile', ylabel= 'Mean Energy [GeV]',\n",
    "                                binning = binning_l['ex'],triangle=triangle,\n",
    "                                logy=True, reference_name='Geant4', y_lim_ratio = y_lim_ratio_l['ex'],\n",
    "                                title='{:d} GeV'.format(energy), y_range= y_range_l['ex'])\n",
    "    #ax0.set_xscale(\"log\")\n",
    "    fig.savefig('./plots/ex_{:d}GeV.pdf'.format(energy))\n",
    "\n",
    "    ### ey ###\n",
    "    weight_dict = {\n",
    "        'Geant4': np.reshape(np.sum(np.reshape(data_full[:,:100], (-1, 10, 10)), 1), -1)/data_full.shape[0],\n",
    "        'GFlash': np.reshape(np.sum(np.reshape(data_orig, (-1, 10, 10)), 1), -1)/data_full.shape[0],\n",
    "        'SQuIRELS': np.reshape(np.sum(np.reshape(data_trafo, (-1, 10, 10)), 1), -1)/data_full.shape[0],\n",
    "    }\n",
    "\n",
    "    feed_dict = {\n",
    "        'Geant4': np.tile(np.arange(0.5, 9.6, 1), data_full.shape[0]),\n",
    "        'GFlash': np.tile(np.arange(0.5, 9.6, 1), data_full.shape[0]),\n",
    "        'SQuIRELS': np.tile(np.arange(0.5, 9.6, 1), data_full.shape[0]),\n",
    "    }\n",
    "\n",
    "\n",
    "    fig,ax0 = HistRoutine(feed_dict,weights = weight_dict,\n",
    "                                label_loc= 'best', density=False,\n",
    "                                xlabel='y Profile', ylabel= 'Mean Energy [GeV]',\n",
    "                                binning = binning_l['ex'],triangle=triangle,\n",
    "                                logy=True, reference_name='Geant4', y_lim_ratio = y_lim_ratio_l['ex'],\n",
    "                                title='{:d} GeV'.format(energy), y_range= y_range_l['ex'])\n",
    "    #ax0.set_xscale(\"log\")\n",
    "    fig.savefig('./plots/ey_{:d}GeV.pdf'.format(energy))\n",
    "\n",
    "\n",
    "    fig,ax0 = ScatterRoutine(xdata=energy_gflash_trafo[:10000,0], ydata=energy_gflash_trafo[:10000,1], \n",
    "                             data_label = 'SQuIRELS-E',\n",
    "                             xlabel='$e_{GF}$',ylabel='$e_{refined}$',\n",
    "                             label_loc='best',title='{:d} GeV'.format(energy))\n",
    "    fig.savefig('./plots/scatter_{:d}GeV.pdf'.format(energy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c611f079",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c002f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa1fe25-d621-448e-bc8f-b9e4629a31df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SDiefenbacher_pytorch201",
   "language": "python",
   "name": "sdiefenbacher_pytorch201"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
